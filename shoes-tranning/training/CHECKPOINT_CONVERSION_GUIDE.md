# Guia de ConversÃ£o de Checkpoints

**Data**: 27/10/2025
**Status**: Implementado

---

## Problema Identificado

Os checkpoints intermediÃ¡rios salvos durante o treinamento nÃ£o estavam aparecendo no frontend da API.

### Causa

Durante o treinamento, o Accelerate salva checkpoints em dois formatos diferentes:

**Checkpoints intermediÃ¡rios** (durante treinamento):
- Salvos em `outputs/*/checkpoints/checkpoint-N/`
- ContÃ©m apenas: `model.safetensors`, `optimizer.bin`, `scheduler.bin`
- Formato: Estado do modelo LoRA (PEFT)
- **NÃƒO** Ã© um pipeline completo

**Checkpoint final** (ao terminar):
- Salvo em `outputs/*/lora_weights/`
- Formato: LoRA weights completo
- Pode ser carregado com `load_lora_weights()`

### O que a API esperava

A API procura por pipelines completos em:
- `outputs/*/final_pipeline/` - Pipeline final com UNet fine-tuned
- `outputs/*/checkpoint_pipelines/checkpoint-N/` - Checkpoints convertidos

---

## SoluÃ§Ã£o Implementada

### 1. Script de ConversÃ£o em Lote

**Arquivo**: `training/scripts/convert_all_checkpoints.py`

Converte todos os checkpoints de um treinamento de uma vez:

```bash
cd training/scripts
python convert_all_checkpoints.py ../outputs/lora_casual_shoes_3000steps_full
```

**SaÃ­da**:
```
Encontrados 3 checkpoints em: ../outputs/.../checkpoints

ğŸ”„ Convertendo checkpoint-1000...
âœ… checkpoint-1000: Convertido com sucesso

ğŸ”„ Convertendo checkpoint-1500...
âœ… checkpoint-1500: Convertido com sucesso

â­ï¸  checkpoint-500: JÃ¡ convertido (use --force para reconverter)

Resumo:
  Convertidos: 2
  Ignorados: 1
  Falhas: 0
  Total: 3
```

**Flags disponÃ­veis**:
- `--force`: Reconverte checkpoints jÃ¡ convertidos

### 2. Estrutura Gerada

ApÃ³s a conversÃ£o:

```
outputs/lora_casual_shoes_3000steps_full/
â”œâ”€â”€ checkpoints/                      # Checkpoints originais (Accelerate)
â”‚   â”œâ”€â”€ checkpoint-500/
â”‚   â”‚   â”œâ”€â”€ model.safetensors        # 3.2GB - Estado do modelo
â”‚   â”‚   â”œâ”€â”€ optimizer.bin            # 12MB - Estado do otimizador
â”‚   â”‚   â”œâ”€â”€ scheduler.bin            # 1.4KB - Estado do scheduler
â”‚   â”‚   â””â”€â”€ random_states_0.pkl      # 14KB - Seeds aleatÃ³rios
â”‚   â”œâ”€â”€ checkpoint-1000/
â”‚   â””â”€â”€ checkpoint-1500/
â”‚
â””â”€â”€ checkpoint_pipelines/             # Checkpoints convertidos (Diffusers)
    â”œâ”€â”€ checkpoint-500/
    â”‚   â”œâ”€â”€ model_index.json         # Ãndice do pipeline
    â”‚   â”œâ”€â”€ unet/
    â”‚   â”‚   â”œâ”€â”€ config.json
    â”‚   â”‚   â””â”€â”€ diffusion_pytorch_model.safetensors
    â”‚   â”œâ”€â”€ text_encoder/
    â”‚   â”œâ”€â”€ vae/
    â”‚   â”œâ”€â”€ tokenizer/
    â”‚   â”œâ”€â”€ scheduler/
    â”‚   â””â”€â”€ checkpoint_metadata.json  # Metadata
    â”œâ”€â”€ checkpoint-1000/
    â””â”€â”€ checkpoint-1500/
```

---

## Como Funciona

### Processo de ConversÃ£o

1. **Carrega modelo base**: Stable Diffusion 1.5
2. **Carrega UNet do checkpoint**: Aplica pesos LoRA treinados
3. **Cria pipeline completo**: Combina UNet + componentes base
4. **Salva no formato Diffusers**: Cria estrutura que a API pode carregar

### Componentes do Pipeline

Cada checkpoint convertido contÃ©m:

- **UNet**: Com pesos LoRA treinados atÃ© o step N
- **Text Encoder**: Modelo base (nÃ£o alterado)
- **VAE**: Modelo base (nÃ£o alterado)
- **Tokenizer**: Modelo base (nÃ£o alterado)
- **Scheduler**: ConfiguraÃ§Ã£o de noise scheduling

---

## Uso na API

### DetecÃ§Ã£o AutomÃ¡tica

A API detecta automaticamente checkpoints convertidos:

```python
# Endpoint: GET /api/models
{
  "models": [
    {
      "name": "lora_casual_shoes_3000steps_full/checkpoint-500",
      "display_name": "Lora Casual Shoes 3000Steps Full (Step 500)",
      "description": "Checkpoint intermediÃ¡rio no step 500",
      "available": true
    },
    {
      "name": "lora_casual_shoes_3000steps_full/checkpoint-1000",
      "display_name": "Lora Casual Shoes 3000Steps Full (Step 1000)",
      "description": "Checkpoint intermediÃ¡rio no step 1000",
      "available": true
    },
    // ...
  ]
}
```

### GeraÃ§Ã£o de Imagens

```bash
curl -X POST http://localhost:8011/api/generate \
  -H "Content-Type: application/json" \
  -d '{
    "model_name": "lora_casual_shoes_3000steps_full/checkpoint-1000",
    "prompt": "casual brown leather shoes, product photo",
    "num_images": 1
  }'
```

---

## ConversÃ£o AutomÃ¡tica Durante Treinamento

### Status Atual

Os checkpoints intermediÃ¡rios **NÃƒO** sÃ£o convertidos automaticamente durante o treinamento por razÃµes de:

1. **EspaÃ§o em disco**: Cada checkpoint convertido ocupa ~3.5GB
2. **Tempo**: ConversÃ£o leva ~30 segundos por checkpoint
3. **InterrupÃ§Ã£o**: Pode atrasar o treinamento

### Quando Converter

**RecomendaÃ§Ãµes**:

âœ… **Converter APÃ“S o treinamento**:
- Quando quiser testar checkpoints especÃ­ficos
- Quando precisar comparar diferentes steps
- Para validaÃ§Ã£o de progresso

âŒ **NÃƒO converter durante treinamento**:
- Durante treinamento ativo
- Se espaÃ§o em disco for limitado
- Se nÃ£o precisar dos checkpoints intermediÃ¡rios

---

## Comandos Ãšteis

### Listar Checkpoints DisponÃ­veis

```bash
ls -lh outputs/*/checkpoints/
```

### Converter Checkpoints de um Treinamento

```bash
python convert_all_checkpoints.py ../outputs/lora_casual_shoes_3000steps_full
```

### Converter Checkpoint EspecÃ­fico

```bash
python convert_checkpoint_to_pipeline.py \
  --checkpoint ../outputs/lora_casual_shoes_3000steps_full/checkpoints/checkpoint-1000 \
  --output ../outputs/lora_casual_shoes_3000steps_full/checkpoint_pipelines/checkpoint-1000
```

### Verificar Modelos na API

```bash
curl -s http://localhost:8011/api/models | python -m json.tool
```

### Limpar Checkpoints Convertidos

```bash
rm -rf outputs/*/checkpoint_pipelines/checkpoint-*
```

---

## Estimativas de EspaÃ§o

### Por Checkpoint

| Componente | Tamanho |
|------------|---------|
| Checkpoint original (Accelerate) | 3.2 GB |
| Checkpoint convertido (Diffusers) | 3.5 GB |
| **Total** | **6.7 GB** |

### Para Treinamento Completo (3000 steps)

Checkpoints salvos a cada 500 steps:

| Step | Original | Convertido | Total |
|------|----------|------------|-------|
| 500 | 3.2 GB | 3.5 GB | 6.7 GB |
| 1000 | 3.2 GB | 3.5 GB | 6.7 GB |
| 1500 | 3.2 GB | 3.5 GB | 6.7 GB |
| 2000 | 3.2 GB | 3.5 GB | 6.7 GB |
| 2500 | 3.2 GB | 3.5 GB | 6.7 GB |
| 3000 | 3.2 GB | 3.5 GB | 6.7 GB |
| **Total** | **19.2 GB** | **21 GB** | **40.2 GB** |

---

## Troubleshooting

### Erro: "Missing keys" durante conversÃ£o

**Mensagem**:
```
WARNING - Missing keys: 686 keys
WARNING - Unexpected keys: 942 keys
```

**ExplicaÃ§Ã£o**: Ã‰ **NORMAL** e esperado. O UNet base tem parÃ¢metros que nÃ£o existem no checkpoint LoRA (e vice-versa).

**AÃ§Ã£o**: Nenhuma. A conversÃ£o foi bem-sucedida.

### Checkpoint nÃ£o aparece na API

**Verificar**:

1. Checkpoint foi convertido?
```bash
ls outputs/*/checkpoint_pipelines/checkpoint-N/
```

2. Tem `model_index.json`?
```bash
cat outputs/*/checkpoint_pipelines/checkpoint-N/model_index.json
```

3. API estÃ¡ rodando?
```bash
curl http://localhost:8011/api/models
```

### EspaÃ§o insuficiente

Se nÃ£o houver espaÃ§o para converter todos:

```bash
# Converter apenas checkpoints especÃ­ficos
python convert_checkpoint_to_pipeline.py \
  --checkpoint ../outputs/.../checkpoints/checkpoint-1500 \
  --output ../outputs/.../checkpoint_pipelines/checkpoint-1500
```

---

## Fluxo de Trabalho Recomendado

### Durante o Treinamento

1. âœ… Deixar checkpoints serem salvos normalmente
2. âœ… Monitorar progresso via logs
3. âŒ NÃƒO converter checkpoints ainda

### ApÃ³s o Treinamento

1. âœ… Analisar loss nos logs
2. âœ… Identificar checkpoints interessantes
3. âœ… Converter checkpoints selecionados:
```bash
python convert_all_checkpoints.py ../outputs/TRAINING_NAME
```
4. âœ… Testar no frontend
5. âœ… Gerar imagens de validaÃ§Ã£o

### Limpeza

ApÃ³s identificar o melhor checkpoint:

```bash
# Manter apenas checkpoints necessÃ¡rios
# Deletar checkpoints intermediÃ¡rios nÃ£o convertidos
rm -rf outputs/*/checkpoints/checkpoint-{500,1000,1500}

# Ou deletar checkpoints convertidos nÃ£o necessÃ¡rios
rm -rf outputs/*/checkpoint_pipelines/checkpoint-{500,1000}
```

---

## PrÃ³ximos Passos

### ImplementaÃ§Ãµes Futuras

- [ ] Script para converter apenas "melhores" checkpoints (baseado em loss)
- [ ] ConversÃ£o incremental (apenas novos checkpoints)
- [ ] CompactaÃ§Ã£o de checkpoints antigos
- [ ] Dashboard para comparar checkpoints visualmente

---

**Criado**: 27/10/2025
**Ãšltima AtualizaÃ§Ã£o**: 27/10/2025
**Autor**: Claude Code
