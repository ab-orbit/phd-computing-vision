{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro",
   "metadata": {},
   "source": [
    "# Classificador CNN Simples para Emoções Faciais (Raiva vs Alegria)\n",
    "\n",
    "## Objetivo Pedagógico\n",
    "\n",
    "Este notebook implementa um classificador binário de emoções usando uma CNN (Convolutional Neural Network) simples.\n",
    "O objetivo é comparar o desempenho de CNNs tradicionais com modelos foundation (como CLIP) em classificação de emoções.\n",
    "\n",
    "### Arquitetura da CNN\n",
    "\n",
    "A arquitetura utilizada é composta por:\n",
    "- **3 blocos convolucionais**: Cada bloco contém uma camada Conv2D seguida de MaxPooling2D\n",
    "  - Conv2D extrai características visuais (bordas, texturas, padrões)\n",
    "  - MaxPooling2D reduz dimensionalidade e adiciona invariância espacial\n",
    "- **Dropout (0.4)**: Regularização para prevenir overfitting\n",
    "- **Camadas densas**: Classificação final baseada nas características extraídas\n",
    "\n",
    "### Metodologia de Avaliação\n",
    "\n",
    "- **30 simulações independentes**: Cada simulação usa um conjunto diferente de 50 imagens por classe\n",
    "- **Métricas estatísticas**: Média e desvio padrão da acurácia permitem avaliar robustez\n",
    "- **Split treino/validação**: 80% treino, 20% validação (dentro de cada simulação)\n",
    "\n",
    "### Conceitos Importantes\n",
    "\n",
    "**Por que usar múltiplas simulações?**\n",
    "- Reduz viés de seleção de amostras específicas\n",
    "- Permite calcular intervalos de confiança\n",
    "- Avalia estabilidade do modelo em diferentes subconjuntos de dados\n",
    "\n",
    "**Por que classificação binária?**\n",
    "- Raiva e alegria são emoções opostas e bem distintas\n",
    "- Facilita comparação com modelos foundation\n",
    "- Permite focar na capacidade de discriminação das características"
   ]
  },
  {
   "cell_type": "code",
   "id": "imports",
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-11-29T13:46:59.012647Z"
    }
   },
   "source": [
    "# Importações necessárias\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from pathlib import Path\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# Configuração para reprodutibilidade\n",
    "# A seed garante que os mesmos resultados sejam obtidos em execuções diferentes\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "# Verifica disponibilidade de GPU\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"GPU disponível:\", tf.config.list_physical_devices('GPU'))\n",
    "print(\"Num GPUs Available:\", len(tf.config.list_physical_devices('GPU')))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "config",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurações do projeto\n",
    "\n",
    "# Caminhos\n",
    "PROJECT_ROOT = Path(\"/projeto-estudo-comparativo\")\n",
    "DATASET_DIR = PROJECT_ROOT / \"datasets\"\n",
    "RESULTS_DIR = PROJECT_ROOT / \"results\" / \"simple_cnn\"\n",
    "MODELS_DIR = PROJECT_ROOT / \"models\" / \"simple_cnn\"\n",
    "\n",
    "# Cria diretórios se não existirem\n",
    "RESULTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "MODELS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Hiperparâmetros\n",
    "# Explicação: Imagens redimensionadas para 128x128 pixels (balanço entre performance e qualidade)\n",
    "IMG_WIDTH = 128\n",
    "IMG_HEIGHT = 128\n",
    "\n",
    "# Explicação: Split de validação - 20% dos dados para validação, 80% para treino\n",
    "VALIDATION_SPLIT = 0.2\n",
    "\n",
    "# Explicação: Batch size - número de imagens processadas simultaneamente\n",
    "# Valores maiores = treinamento mais rápido mas requer mais memória\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Explicação: Número máximo de épocas de treinamento\n",
    "# Early stopping pode interromper antes se não houver melhoria\n",
    "EPOCHS = 50\n",
    "\n",
    "# Número de simulações\n",
    "NUM_SIMULATIONS = 30\n",
    "\n",
    "# Classes\n",
    "CLASSES = ['alegria', 'raiva']\n",
    "NUM_CLASSES = len(CLASSES)\n",
    "\n",
    "print(f\"Configuração carregada:\")\n",
    "print(f\"  Dataset: {DATASET_DIR}\")\n",
    "print(f\"  Resultados: {RESULTS_DIR}\")\n",
    "print(f\"  Modelos: {MODELS_DIR}\")\n",
    "print(f\"  Imagens: {IMG_WIDTH}x{IMG_HEIGHT}\")\n",
    "print(f\"  Classes: {CLASSES}\")\n",
    "print(f\"  Simulações: {NUM_SIMULATIONS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "model_architecture",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_simple_cnn_model():\n",
    "    \"\"\"\n",
    "    Cria um modelo CNN simples para classificação binária de emoções.\n",
    "    \n",
    "    Arquitetura detalhada:\n",
    "    ----------------------\n",
    "    1. Input Layer (128x128x3): Imagens RGB\n",
    "    \n",
    "    2. Rescaling Layer: Normaliza pixels de [0, 255] para [0, 1]\n",
    "       - Facilita convergência do treinamento\n",
    "       - Evita problemas de gradientes explodindo/desaparecendo\n",
    "    \n",
    "    3. Bloco Convolucional 1:\n",
    "       - Conv2D(32 filtros, kernel 3x3): Detecta características básicas (bordas, cantos)\n",
    "       - MaxPooling2D(2x2): Reduz dimensionalidade, mantém características importantes\n",
    "       - Output: 64x64x32\n",
    "    \n",
    "    4. Bloco Convolucional 2:\n",
    "       - Conv2D(64 filtros, kernel 3x3): Detecta padrões mais complexos (olhos, boca)\n",
    "       - MaxPooling2D(2x2): Reduz dimensionalidade\n",
    "       - Output: 32x32x64\n",
    "    \n",
    "    5. Bloco Convolucional 3:\n",
    "       - Conv2D(128 filtros, kernel 3x3): Detecta características de alto nível (expressões)\n",
    "       - MaxPooling2D(2x2): Reduz dimensionalidade\n",
    "       - Output: 16x16x128\n",
    "    \n",
    "    6. Dropout(0.4): Desativa aleatoriamente 40% dos neurônios durante treino\n",
    "       - Previne overfitting\n",
    "       - Força rede a aprender características robustas\n",
    "    \n",
    "    7. Flatten: Converte tensor 3D em vetor 1D (16*16*128 = 32768 valores)\n",
    "    \n",
    "    8. Dense(64, relu): Camada totalmente conectada\n",
    "       - Combina características extraídas\n",
    "       - ReLU adiciona não-linearidade\n",
    "    \n",
    "    9. Dense(1, sigmoid): Camada de saída para classificação binária\n",
    "       - Sigmoid produz probabilidade entre 0 e 1\n",
    "       - 0 = raiva, 1 = alegria (ou vice-versa)\n",
    "    \n",
    "    Total de parâmetros: ~2.1M parâmetros treináveis\n",
    "    \n",
    "    Returns:\n",
    "        modelo Keras compilado\n",
    "    \"\"\"\n",
    "    model = keras.Sequential([\n",
    "        # Input\n",
    "        layers.Input(shape=(IMG_WIDTH, IMG_HEIGHT, 3)),\n",
    "        \n",
    "        # Normalização\n",
    "        layers.Rescaling(1./255),\n",
    "        \n",
    "        # Bloco 1: Características básicas\n",
    "        layers.Conv2D(32, 3, padding='same', activation='relu', name='conv1'),\n",
    "        layers.MaxPooling2D(2, name='pool1'),\n",
    "        \n",
    "        # Bloco 2: Características intermediárias\n",
    "        layers.Conv2D(64, 3, padding='same', activation='relu', name='conv2'),\n",
    "        layers.MaxPooling2D(2, name='pool2'),\n",
    "        \n",
    "        # Bloco 3: Características de alto nível\n",
    "        layers.Conv2D(128, 3, padding='same', activation='relu', name='conv3'),\n",
    "        layers.MaxPooling2D(2, name='pool3'),\n",
    "        \n",
    "        # Regularização\n",
    "        layers.Dropout(0.4, name='dropout'),\n",
    "        \n",
    "        # Classificação\n",
    "        layers.Flatten(name='flatten'),\n",
    "        layers.Dense(64, activation='relu', name='dense1'),\n",
    "        \n",
    "        # Saída binária (1 neurônio com sigmoid para classificação binária)\n",
    "        layers.Dense(1, activation='sigmoid', name='output')\n",
    "    ])\n",
    "    \n",
    "    # Compilação do modelo\n",
    "    # Explicação da loss function:\n",
    "    # - binary_crossentropy: Apropriada para classificação binária\n",
    "    # - Mede a diferença entre probabilidades preditas e labels verdadeiros\n",
    "    #\n",
    "    # Explicação do otimizador:\n",
    "    # - Adam: Otimizador adaptativo, funciona bem na maioria dos casos\n",
    "    # - Combina vantagens de RMSprop e SGD com momentum\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy', 'precision', 'recall']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Cria e exibe sumário do modelo\n",
    "model = create_simple_cnn_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "data_loading",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_simulation_data(simulation_num):\n",
    "    \"\"\"\n",
    "    Carrega dados de uma simulação específica.\n",
    "    \n",
    "    O dataset está organizado em:\n",
    "    datasets/\n",
    "      sim01/\n",
    "        raiva/     [50 imagens]\n",
    "        alegria/   [50 imagens]\n",
    "      sim02/\n",
    "        ...\n",
    "    \n",
    "    Keras image_dataset_from_directory automaticamente:\n",
    "    - Carrega imagens dos subdiretórios\n",
    "    - Cria labels baseado nos nomes das pastas\n",
    "    - Redimensiona imagens para o tamanho especificado\n",
    "    - Divide em treino/validação conforme validation_split\n",
    "    \n",
    "    Args:\n",
    "        simulation_num: Número da simulação (1-30)\n",
    "    \n",
    "    Returns:\n",
    "        train_ds, val_ds: Datasets de treino e validação\n",
    "    \"\"\"\n",
    "    sim_dir = DATASET_DIR / f\"sim{simulation_num:02d}\"\n",
    "    \n",
    "    if not sim_dir.exists():\n",
    "        raise FileNotFoundError(f\"Simulação {simulation_num} não encontrada em {sim_dir}\")\n",
    "    \n",
    "    # Dataset de treino\n",
    "    # Explicação do validation_split:\n",
    "    # - 0.2 significa 20% dos dados para validação\n",
    "    # - subset=\"training\" seleciona os 80% para treino\n",
    "    train_ds = keras.utils.image_dataset_from_directory(\n",
    "        sim_dir,\n",
    "        validation_split=VALIDATION_SPLIT,\n",
    "        subset=\"training\",\n",
    "        seed=SEED,\n",
    "        image_size=(IMG_WIDTH, IMG_HEIGHT),\n",
    "        batch_size=BATCH_SIZE,\n",
    "        label_mode='binary'  # Classificação binária: 0 ou 1\n",
    "    )\n",
    "    \n",
    "    # Dataset de validação\n",
    "    val_ds = keras.utils.image_dataset_from_directory(\n",
    "        sim_dir,\n",
    "        validation_split=VALIDATION_SPLIT,\n",
    "        subset=\"validation\",\n",
    "        seed=SEED,\n",
    "        image_size=(IMG_WIDTH, IMG_HEIGHT),\n",
    "        batch_size=BATCH_SIZE,\n",
    "        label_mode='binary'\n",
    "    )\n",
    "    \n",
    "    # Otimizações de performance\n",
    "    # Explicação:\n",
    "    # - cache(): Mantém imagens em memória após primeira época (acelera treinamento)\n",
    "    # - shuffle(1000): Embaralha dados para evitar viés de ordem\n",
    "    # - prefetch(): Prepara próximo batch enquanto treina o atual (paralelização)\n",
    "    train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "    val_ds = val_ds.cache().prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "    \n",
    "    return train_ds, val_ds\n",
    "\n",
    "# Teste de carregamento\n",
    "print(\"Testando carregamento de dados da simulação 01...\")\n",
    "train_ds, val_ds = load_simulation_data(1)\n",
    "print(f\"Dataset de treino: {train_ds}\")\n",
    "print(f\"Dataset de validação: {val_ds}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "training_functions",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_simulation(simulation_num, verbose=1):\n",
    "    \"\"\"\n",
    "    Treina o modelo em uma simulação específica.\n",
    "    \n",
    "    Pipeline de treinamento:\n",
    "    1. Carrega dados da simulação\n",
    "    2. Cria novo modelo (inicialização aleatória)\n",
    "    3. Configura callbacks (early stopping, model checkpoint)\n",
    "    4. Treina modelo\n",
    "    5. Salva modelo e histórico\n",
    "    6. Retorna métricas finais\n",
    "    \n",
    "    Args:\n",
    "        simulation_num: Número da simulação (1-30)\n",
    "        verbose: Nível de verbosidade (0=silencioso, 1=barra de progresso, 2=uma linha por época)\n",
    "    \n",
    "    Returns:\n",
    "        dict com métricas da simulação\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"Iniciando Simulação {simulation_num:02d}/{NUM_SIMULATIONS}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    # 1. Carrega dados\n",
    "    train_ds, val_ds = load_simulation_data(simulation_num)\n",
    "    \n",
    "    # 2. Cria novo modelo\n",
    "    # Importante: Cada simulação usa um modelo com pesos iniciais diferentes\n",
    "    model = create_simple_cnn_model()\n",
    "    \n",
    "    # 3. Configura callbacks\n",
    "    # Early Stopping: Para treinamento se validação não melhorar por N épocas\n",
    "    # Explicação:\n",
    "    # - monitor='val_loss': Monitora loss de validação\n",
    "    # - patience=5: Espera 5 épocas sem melhoria antes de parar\n",
    "    # - restore_best_weights=True: Restaura pesos da melhor época\n",
    "    early_stop = keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=5,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Model Checkpoint: Salva melhor modelo durante treinamento\n",
    "    model_path = MODELS_DIR / f\"sim{simulation_num:02d}_best.keras\"\n",
    "    checkpoint = keras.callbacks.ModelCheckpoint(\n",
    "        model_path,\n",
    "        monitor='val_accuracy',\n",
    "        save_best_only=True,\n",
    "        verbose=0\n",
    "    )\n",
    "    \n",
    "    # 4. Treina modelo\n",
    "    history = model.fit(\n",
    "        train_ds,\n",
    "        validation_data=val_ds,\n",
    "        epochs=EPOCHS,\n",
    "        callbacks=[early_stop, checkpoint],\n",
    "        verbose=verbose\n",
    "    )\n",
    "    \n",
    "    # 5. Salva histórico de treinamento\n",
    "    history_path = RESULTS_DIR / f\"sim{simulation_num:02d}_history.json\"\n",
    "    with open(history_path, 'w') as f:\n",
    "        # Converte arrays numpy para listas para serialização JSON\n",
    "        history_dict = {key: [float(val) for val in values] \n",
    "                       for key, values in history.history.items()}\n",
    "        json.dump(history_dict, f, indent=2)\n",
    "    \n",
    "    # 6. Coleta métricas finais\n",
    "    # Usa métricas da última época (com best weights restaurados)\n",
    "    final_metrics = {\n",
    "        'simulation': simulation_num,\n",
    "        'train_accuracy': float(history.history['accuracy'][-1]),\n",
    "        'val_accuracy': float(history.history['val_accuracy'][-1]),\n",
    "        'train_loss': float(history.history['loss'][-1]),\n",
    "        'val_loss': float(history.history['val_loss'][-1]),\n",
    "        'epochs_trained': len(history.history['loss']),\n",
    "        'model_path': str(model_path),\n",
    "        'timestamp': datetime.now().isoformat()\n",
    "    }\n",
    "    \n",
    "    print(f\"\\nSimulação {simulation_num:02d} concluída:\")\n",
    "    print(f\"  Acurácia Treino: {final_metrics['train_accuracy']:.4f}\")\n",
    "    print(f\"  Acurácia Validação: {final_metrics['val_accuracy']:.4f}\")\n",
    "    print(f\"  Épocas: {final_metrics['epochs_trained']}\")\n",
    "    \n",
    "    return final_metrics\n",
    "\n",
    "# Teste de treinamento em uma simulação\n",
    "print(\"Executando treinamento de teste na simulação 01...\")\n",
    "# Descomente a linha abaixo para executar teste\n",
    "# test_metrics = train_simulation(1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "run_all_simulations",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_all_simulations():\n",
    "    \"\"\"\n",
    "    Executa treinamento em todas as 30 simulações.\n",
    "    \n",
    "    Este processo pode levar várias horas dependendo do hardware:\n",
    "    - Com GPU: ~5-10 min por simulação = 2.5-5 horas total\n",
    "    - Sem GPU: ~15-30 min por simulação = 7.5-15 horas total\n",
    "    \n",
    "    Salva resultados consolidados em CSV para análise posterior.\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame com métricas de todas as simulações\n",
    "    \"\"\"\n",
    "    all_results = []\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"INICIANDO TREINAMENTO DE TODAS AS SIMULAÇÕES\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"Total de simulações: {NUM_SIMULATIONS}\")\n",
    "    print(f\"Epochs máximos por simulação: {EPOCHS}\")\n",
    "    print(f\"Early stopping: {5} épocas de paciência\")\n",
    "    print(\"=\"*70 + \"\\n\")\n",
    "    \n",
    "    start_time = datetime.now()\n",
    "    \n",
    "    for sim_num in range(1, NUM_SIMULATIONS + 1):\n",
    "        try:\n",
    "            # Treina simulação\n",
    "            metrics = train_simulation(sim_num, verbose=1)\n",
    "            all_results.append(metrics)\n",
    "            \n",
    "            # Salva resultados parciais (segurança em caso de interrupção)\n",
    "            partial_df = pd.DataFrame(all_results)\n",
    "            partial_df.to_csv(RESULTS_DIR / \"partial_results.csv\", index=False)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"\\nERRO na simulação {sim_num}: {e}\")\n",
    "            print(\"Continuando com próxima simulação...\\n\")\n",
    "            continue\n",
    "    \n",
    "    end_time = datetime.now()\n",
    "    duration = end_time - start_time\n",
    "    \n",
    "    # Converte para DataFrame\n",
    "    results_df = pd.DataFrame(all_results)\n",
    "    \n",
    "    # Salva resultados finais\n",
    "    results_path = RESULTS_DIR / \"all_simulations_results.csv\"\n",
    "    results_df.to_csv(results_path, index=False)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"TODAS AS SIMULAÇÕES CONCLUÍDAS\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"Tempo total: {duration}\")\n",
    "    print(f\"Tempo médio por simulação: {duration / len(all_results)}\")\n",
    "    print(f\"Resultados salvos em: {results_path}\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    return results_df\n",
    "\n",
    "# EXECUÇÃO: Descomente a linha abaixo para executar todas as simulações\n",
    "# ATENÇÃO: Este processo pode levar várias horas!\n",
    "# results_df = run_all_simulations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "analysis_functions",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_results(results_df):\n",
    "    \"\"\"\n",
    "    Analisa resultados das simulações e gera estatísticas.\n",
    "    \n",
    "    Calcula:\n",
    "    - Média e desvio padrão de acurácia\n",
    "    - Intervalo de confiança (95%)\n",
    "    - Melhor e pior simulação\n",
    "    - Distribuição de épocas de convergência\n",
    "    \n",
    "    Args:\n",
    "        results_df: DataFrame com resultados das simulações\n",
    "    \n",
    "    Returns:\n",
    "        dict com estatísticas agregadas\n",
    "    \"\"\"\n",
    "    stats = {\n",
    "        # Acurácia de validação (principal métrica)\n",
    "        'val_accuracy_mean': results_df['val_accuracy'].mean(),\n",
    "        'val_accuracy_std': results_df['val_accuracy'].std(),\n",
    "        'val_accuracy_min': results_df['val_accuracy'].min(),\n",
    "        'val_accuracy_max': results_df['val_accuracy'].max(),\n",
    "        \n",
    "        # Intervalo de confiança 95% (assumindo distribuição normal)\n",
    "        # IC = média ± 1.96 * (desvio_padrão / sqrt(n))\n",
    "        'val_accuracy_ci_lower': results_df['val_accuracy'].mean() - \n",
    "                                 1.96 * results_df['val_accuracy'].std() / np.sqrt(len(results_df)),\n",
    "        'val_accuracy_ci_upper': results_df['val_accuracy'].mean() + \n",
    "                                 1.96 * results_df['val_accuracy'].std() / np.sqrt(len(results_df)),\n",
    "        \n",
    "        # Épocas de treinamento\n",
    "        'epochs_mean': results_df['epochs_trained'].mean(),\n",
    "        'epochs_std': results_df['epochs_trained'].std(),\n",
    "        \n",
    "        # Loss de validação\n",
    "        'val_loss_mean': results_df['val_loss'].mean(),\n",
    "        'val_loss_std': results_df['val_loss'].std(),\n",
    "        \n",
    "        # Número de simulações\n",
    "        'num_simulations': len(results_df)\n",
    "    }\n",
    "    \n",
    "    # Identifica melhor e pior simulação\n",
    "    best_idx = results_df['val_accuracy'].idxmax()\n",
    "    worst_idx = results_df['val_accuracy'].idxmin()\n",
    "    \n",
    "    stats['best_simulation'] = int(results_df.loc[best_idx, 'simulation'])\n",
    "    stats['best_accuracy'] = float(results_df.loc[best_idx, 'val_accuracy'])\n",
    "    stats['worst_simulation'] = int(results_df.loc[worst_idx, 'simulation'])\n",
    "    stats['worst_accuracy'] = float(results_df.loc[worst_idx, 'val_accuracy'])\n",
    "    \n",
    "    # Exibe resumo\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"ANÁLISE ESTATÍSTICA DOS RESULTADOS\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"\\nSimulações analisadas: {stats['num_simulations']}\")\n",
    "    print(f\"\\nAcurácia de Validação:\")\n",
    "    print(f\"  Média: {stats['val_accuracy_mean']:.4f} ± {stats['val_accuracy_std']:.4f}\")\n",
    "    print(f\"  IC 95%: [{stats['val_accuracy_ci_lower']:.4f}, {stats['val_accuracy_ci_upper']:.4f}]\")\n",
    "    print(f\"  Min: {stats['val_accuracy_min']:.4f} (sim {stats['worst_simulation']:02d})\")\n",
    "    print(f\"  Max: {stats['val_accuracy_max']:.4f} (sim {stats['best_simulation']:02d})\")\n",
    "    print(f\"\\nÉpocas de Treinamento:\")\n",
    "    print(f\"  Média: {stats['epochs_mean']:.1f} ± {stats['epochs_std']:.1f}\")\n",
    "    print(f\"\\nLoss de Validação:\")\n",
    "    print(f\"  Média: {stats['val_loss_mean']:.4f} ± {stats['val_loss_std']:.4f}\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Salva estatísticas\n",
    "    stats_path = RESULTS_DIR / \"statistical_summary.json\"\n",
    "    with open(stats_path, 'w') as f:\n",
    "        json.dump(stats, f, indent=2)\n",
    "    print(f\"\\nEstatísticas salvas em: {stats_path}\")\n",
    "    \n",
    "    return stats\n",
    "\n",
    "# Exemplo de uso (após executar simulações)\n",
    "# stats = analyze_results(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "visualization",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(results_df):\n",
    "    \"\"\"\n",
    "    Cria visualizações dos resultados das simulações.\n",
    "    \n",
    "    Gera 4 gráficos:\n",
    "    1. Distribuição de acurácias (histograma)\n",
    "    2. Acurácia por simulação (linha)\n",
    "    3. Treino vs Validação (scatter)\n",
    "    4. Épocas de convergência (box plot)\n",
    "    \n",
    "    Args:\n",
    "        results_df: DataFrame com resultados das simulações\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    \n",
    "    # 1. Distribuição de acurácias\n",
    "    ax = axes[0, 0]\n",
    "    ax.hist(results_df['val_accuracy'], bins=15, edgecolor='black', alpha=0.7)\n",
    "    ax.axvline(results_df['val_accuracy'].mean(), color='red', \n",
    "               linestyle='--', linewidth=2, label='Média')\n",
    "    ax.set_xlabel('Acurácia de Validação')\n",
    "    ax.set_ylabel('Frequência')\n",
    "    ax.set_title('Distribuição de Acurácias (30 Simulações)')\n",
    "    ax.legend()\n",
    "    ax.grid(alpha=0.3)\n",
    "    \n",
    "    # 2. Acurácia por simulação\n",
    "    ax = axes[0, 1]\n",
    "    ax.plot(results_df['simulation'], results_df['val_accuracy'], \n",
    "            marker='o', linewidth=1, markersize=4)\n",
    "    ax.axhline(results_df['val_accuracy'].mean(), color='red', \n",
    "               linestyle='--', linewidth=2, label='Média')\n",
    "    ax.fill_between(results_df['simulation'],\n",
    "                     results_df['val_accuracy'].mean() - results_df['val_accuracy'].std(),\n",
    "                     results_df['val_accuracy'].mean() + results_df['val_accuracy'].std(),\n",
    "                     alpha=0.2, color='red', label='±1 Desvio Padrão')\n",
    "    ax.set_xlabel('Número da Simulação')\n",
    "    ax.set_ylabel('Acurácia de Validação')\n",
    "    ax.set_title('Acurácia por Simulação')\n",
    "    ax.legend()\n",
    "    ax.grid(alpha=0.3)\n",
    "    \n",
    "    # 3. Treino vs Validação\n",
    "    ax = axes[1, 0]\n",
    "    ax.scatter(results_df['train_accuracy'], results_df['val_accuracy'], \n",
    "               alpha=0.6, s=50)\n",
    "    # Linha de referência (treino = validação)\n",
    "    min_val = min(results_df['train_accuracy'].min(), results_df['val_accuracy'].min())\n",
    "    max_val = max(results_df['train_accuracy'].max(), results_df['val_accuracy'].max())\n",
    "    ax.plot([min_val, max_val], [min_val, max_val], \n",
    "            'r--', linewidth=2, label='Linha Ideal')\n",
    "    ax.set_xlabel('Acurácia de Treino')\n",
    "    ax.set_ylabel('Acurácia de Validação')\n",
    "    ax.set_title('Treino vs Validação (Detecção de Overfitting)')\n",
    "    ax.legend()\n",
    "    ax.grid(alpha=0.3)\n",
    "    \n",
    "    # 4. Épocas de convergência\n",
    "    ax = axes[1, 1]\n",
    "    bp = ax.boxplot([results_df['epochs_trained']], \n",
    "                     labels=['Épocas'], patch_artist=True)\n",
    "    bp['boxes'][0].set_facecolor('lightblue')\n",
    "    ax.set_ylabel('Número de Épocas')\n",
    "    ax.set_title('Distribuição de Épocas de Convergência')\n",
    "    ax.grid(alpha=0.3, axis='y')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Salva figura\n",
    "    fig_path = RESULTS_DIR / \"results_visualization.png\"\n",
    "    plt.savefig(fig_path, dpi=300, bbox_inches='tight')\n",
    "    print(f\"Visualização salva em: {fig_path}\")\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "# Exemplo de uso\n",
    "# plot_results(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load_and_analyze",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Célula para carregar e analisar resultados existentes\n",
    "# Útil se você já executou as simulações e quer apenas ver os resultados\n",
    "\n",
    "def load_existing_results():\n",
    "    \"\"\"\n",
    "    Carrega resultados de simulações já executadas.\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame com resultados ou None se não existir\n",
    "    \"\"\"\n",
    "    results_path = RESULTS_DIR / \"all_simulations_results.csv\"\n",
    "    \n",
    "    if not results_path.exists():\n",
    "        print(f\"Arquivo de resultados não encontrado: {results_path}\")\n",
    "        print(\"Execute run_all_simulations() primeiro.\")\n",
    "        return None\n",
    "    \n",
    "    df = pd.read_csv(results_path)\n",
    "    print(f\"Resultados carregados: {len(df)} simulações\")\n",
    "    return df\n",
    "\n",
    "# Carrega resultados existentes\n",
    "# results_df = load_existing_results()\n",
    "\n",
    "# Se existir, analisa e visualiza\n",
    "# if results_df is not None:\n",
    "#     stats = analyze_results(results_df)\n",
    "#     plot_results(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conclusion",
   "metadata": {},
   "source": [
    "## Próximos Passos\n",
    "\n",
    "Após executar todas as simulações e analisar os resultados:\n",
    "\n",
    "1. **Comparação com Foundation Models**: Compare os resultados desta CNN com modelos CLIP ou outros foundation models\n",
    "\n",
    "2. **Análise de Erros**: Investigue quais imagens foram classificadas incorretamente\n",
    "\n",
    "3. **Interpretabilidade**: Use técnicas como Grad-CAM para visualizar quais regiões da imagem a CNN usa para classificação\n",
    "\n",
    "4. **Otimização**: Experimente diferentes arquiteturas, hiperparâmetros ou técnicas de data augmentation\n",
    "\n",
    "5. **Documentação**: Documente achados e prepare relatório comparativo\n",
    "\n",
    "## Conceitos Aprendidos\n",
    "\n",
    "- Arquitetura de CNNs para classificação de imagens\n",
    "- Importância de múltiplas simulações para avaliação robusta\n",
    "- Técnicas de regularização (Dropout, Early Stopping)\n",
    "- Análise estatística de resultados experimentais\n",
    "- Pipeline completo de ML: dados → treino → validação → análise"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
